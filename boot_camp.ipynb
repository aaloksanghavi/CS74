{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downloading Python Libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can install things within a notebook by using the ! notation\n",
    "!pip install pandas scikit-learn numpy nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading in the dataset file using Pandas\n",
    "- This loads the data into a Pandas dataframe object. \n",
    "- Dataframe objects provide many functions which make data wrangling easier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring the data\n",
    "- Available features: ['reviewerID', 'amazon-id', 'helpful', 'unixReviewTime', 'reviewText', 'reviewTime', 'summary', 'price', 'categories', 'root-genre', 'title', 'artist', 'label', 'first-release-year', 'songs', 'salesRank','related']\n",
    "- The target variable is 'overall', which is the album's star rating on Amazon. This variable will dictate what you are predicting. \n",
    "- reviewerID-- This is a number identifying a specific Amazon user. \n",
    "- amazon-id-- This is the id of the product (album). \n",
    "- helpful-- This is a fraction in the form of a list. For example, [2,3] means 2 out of three people found the review helpful. \n",
    "- unixReviewTime/reviewTime-- When the review was posted. \n",
    "- reviewText-- This is the full textual review of the album by a given user. **important!! \n",
    "- summary-- A summary of the review. \n",
    "- price-- The price of the album on Amazon. \n",
    "- categories-- Which genres the album is listed under on Amazon. \n",
    "- root-genre-- Primary genre of the album. \n",
    "- title-- Title of album (hashed)\n",
    "- artist-- Artist name (hashed)\n",
    "- first-release-year-- The year the album was released. \n",
    "- songs-- All of the id numbers for each song on the album. \n",
    "- salesRank-- The sales ranking of the album on Amazon. For example, the #1 album on Amazon will have value 1. \n",
    "- related-- This is the \"users also bought\" section on Amazon. Releated contains the amazon ids of the related albums. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>amazon-id</th>\n",
       "      <th>helpful</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>overall</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>summary</th>\n",
       "      <th>price</th>\n",
       "      <th>categories</th>\n",
       "      <th>root-genre</th>\n",
       "      <th>title</th>\n",
       "      <th>artist</th>\n",
       "      <th>label</th>\n",
       "      <th>first-release-year</th>\n",
       "      <th>songs</th>\n",
       "      <th>salesRank</th>\n",
       "      <th>related</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-4984057859803657856</td>\n",
       "      <td>1877521326299865484</td>\n",
       "      <td>[2, 2]</td>\n",
       "      <td>1302739200</td>\n",
       "      <td>Very nice music for practicing my Tai Chi. I d...</td>\n",
       "      <td>4</td>\n",
       "      <td>04 14, 2011</td>\n",
       "      <td>Beautiful</td>\n",
       "      <td>16.47</td>\n",
       "      <td>['CDs &amp; Vinyl', 'New Age']</td>\n",
       "      <td>New Age</td>\n",
       "      <td>-3267874170410107454</td>\n",
       "      <td>-7180760356347753735</td>\n",
       "      <td>Cdbaby/Cdbaby</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[7058439142327364074, 6037075874942075284, 852...</td>\n",
       "      <td>27222</td>\n",
       "      <td>{'also_bought': [-404470919165672227, 11968160...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9136764282801708742</td>\n",
       "      <td>1877521326299865484</td>\n",
       "      <td>[11, 11]</td>\n",
       "      <td>1180396800</td>\n",
       "      <td>I recently starting doing Tai Chi which I love...</td>\n",
       "      <td>5</td>\n",
       "      <td>05 29, 2007</td>\n",
       "      <td>Tranquillity In Motion !!!</td>\n",
       "      <td>16.47</td>\n",
       "      <td>['CDs &amp; Vinyl', 'New Age']</td>\n",
       "      <td>New Age</td>\n",
       "      <td>-3267874170410107454</td>\n",
       "      <td>-7180760356347753735</td>\n",
       "      <td>Cdbaby/Cdbaby</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[7058439142327364074, 6037075874942075284, 852...</td>\n",
       "      <td>27222</td>\n",
       "      <td>{'also_bought': [-404470919165672227, 11968160...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2164551966908582519</td>\n",
       "      <td>1877521326299865484</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>1361404800</td>\n",
       "      <td>My wife uses it for her class room the kids lo...</td>\n",
       "      <td>5</td>\n",
       "      <td>02 21, 2013</td>\n",
       "      <td>Great Stuff</td>\n",
       "      <td>16.47</td>\n",
       "      <td>['CDs &amp; Vinyl', 'New Age']</td>\n",
       "      <td>New Age</td>\n",
       "      <td>-3267874170410107454</td>\n",
       "      <td>-7180760356347753735</td>\n",
       "      <td>Cdbaby/Cdbaby</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[7058439142327364074, 6037075874942075284, 852...</td>\n",
       "      <td>27222</td>\n",
       "      <td>{'also_bought': [-404470919165672227, 11968160...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            reviewerID            amazon-id   helpful  unixReviewTime  \\\n",
       "0 -4984057859803657856  1877521326299865484    [2, 2]      1302739200   \n",
       "1  9136764282801708742  1877521326299865484  [11, 11]      1180396800   \n",
       "2  2164551966908582519  1877521326299865484    [0, 0]      1361404800   \n",
       "\n",
       "                                          reviewText  overall   reviewTime  \\\n",
       "0  Very nice music for practicing my Tai Chi. I d...        4  04 14, 2011   \n",
       "1  I recently starting doing Tai Chi which I love...        5  05 29, 2007   \n",
       "2  My wife uses it for her class room the kids lo...        5  02 21, 2013   \n",
       "\n",
       "                      summary  price                  categories root-genre  \\\n",
       "0                   Beautiful  16.47  ['CDs & Vinyl', 'New Age']    New Age   \n",
       "1  Tranquillity In Motion !!!  16.47  ['CDs & Vinyl', 'New Age']    New Age   \n",
       "2                 Great Stuff  16.47  ['CDs & Vinyl', 'New Age']    New Age   \n",
       "\n",
       "                 title               artist          label  \\\n",
       "0 -3267874170410107454 -7180760356347753735  Cdbaby/Cdbaby   \n",
       "1 -3267874170410107454 -7180760356347753735  Cdbaby/Cdbaby   \n",
       "2 -3267874170410107454 -7180760356347753735  Cdbaby/Cdbaby   \n",
       "\n",
       "   first-release-year                                              songs  \\\n",
       "0                 NaN  [7058439142327364074, 6037075874942075284, 852...   \n",
       "1                 NaN  [7058439142327364074, 6037075874942075284, 852...   \n",
       "2                 NaN  [7058439142327364074, 6037075874942075284, 852...   \n",
       "\n",
       "   salesRank                                            related  \n",
       "0      27222  {'also_bought': [-404470919165672227, 11968160...  \n",
       "1      27222  {'also_bought': [-404470919165672227, 11968160...  \n",
       "2      27222  {'also_bought': [-404470919165672227, 11968160...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# .head(3) simply returns the top-3 rows from a dataframe\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accessing data using pandas \n",
    "##### Below are some of the basic pandas functions you want to become familiar with. (Of course, you don't have to use pandas, I just believe it will make your life much easier. )\n",
    "- df['column name'] allows you to return columns by name\n",
    "- df.iloc[int] allows you to return rows by index. \n",
    "- df[['column 1', 'column2']] allows you to return a subset of columns from the data frame. \n",
    "- df.shape returns a tuple with the number of (rows, columns) which in a ML context means (number of samples, number of features)\n",
    "- df['new column'] = 1D array of equal length, makes a new column called 'new column'\n",
    "\n",
    "Note: I call .head() on the examples below to save space and not put the full column in the notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4\n",
       "1    5\n",
       "2    5\n",
       "3    5\n",
       "4    5\n",
       "Name: overall, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['overall'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>amazon-id</th>\n",
       "      <th>overall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1877521326299865484</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1877521326299865484</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1877521326299865484</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1877521326299865484</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1877521326299865484</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             amazon-id  overall\n",
       "0  1877521326299865484        4\n",
       "1  1877521326299865484        5\n",
       "2  1877521326299865484        5\n",
       "3  1877521326299865484        5\n",
       "4  1877521326299865484        5"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['amazon-id', 'overall']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "reviewerID                                         -4984057859803657856\n",
       "amazon-id                                           1877521326299865484\n",
       "helpful                                                          [2, 2]\n",
       "unixReviewTime                                               1302739200\n",
       "reviewText            Very nice music for practicing my Tai Chi. I d...\n",
       "overall                                                               4\n",
       "reviewTime                                                  04 14, 2011\n",
       "summary                                                       Beautiful\n",
       "price                                                             16.47\n",
       "categories                                   ['CDs & Vinyl', 'New Age']\n",
       "root-genre                                                      New Age\n",
       "title                                              -3267874170410107454\n",
       "artist                                             -7180760356347753735\n",
       "label                                                     Cdbaby/Cdbaby\n",
       "first-release-year                                                  NaN\n",
       "songs                 [7058439142327364074, 6037075874942075284, 852...\n",
       "salesRank                                                         27222\n",
       "related               {'also_bought': [-404470919165672227, 11968160...\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 111098 Number of Features: 18\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of samples: {} Number of Features: {}\".format(df.shape[0], df.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pandas data cleaning example\n",
    " - df.isna() returns a boolean array with a length equal to the number of rows in the data frame. If df.isna()[10] is True, that means row 10 has a null value. \n",
    "     - This logic works the same for df.notna() \n",
    " - If we pass a boolean array to df, it will return only the rows where values are True.\n",
    " \n",
    " What we do below is only extract the rows where we have the first-release-year information. Rows where that value is nan are discarded. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(111098, 18)\n",
      "(99826, 18)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>amazon-id</th>\n",
       "      <th>helpful</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>overall</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>summary</th>\n",
       "      <th>price</th>\n",
       "      <th>categories</th>\n",
       "      <th>root-genre</th>\n",
       "      <th>title</th>\n",
       "      <th>artist</th>\n",
       "      <th>label</th>\n",
       "      <th>first-release-year</th>\n",
       "      <th>songs</th>\n",
       "      <th>salesRank</th>\n",
       "      <th>related</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>-3029154682982670675</td>\n",
       "      <td>2828769427501176858</td>\n",
       "      <td>[13, 13]</td>\n",
       "      <td>1274486400</td>\n",
       "      <td>When I was in Music School at Stetson Universi...</td>\n",
       "      <td>5</td>\n",
       "      <td>05 22, 2010</td>\n",
       "      <td>A Great Teaching tool</td>\n",
       "      <td>15.00</td>\n",
       "      <td>['CDs &amp; Vinyl', 'Classical', 'Sacred &amp; Religio...</td>\n",
       "      <td>Classical</td>\n",
       "      <td>-3686601028207514605</td>\n",
       "      <td>-1412275221690118390</td>\n",
       "      <td>Solesmes</td>\n",
       "      <td>2002.0</td>\n",
       "      <td>[-5278554366520980165, 1031059927497114547, -8...</td>\n",
       "      <td>171890</td>\n",
       "      <td>{'also_bought': [-2564721328448647001, 4039811...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>-6276416742486014581</td>\n",
       "      <td>1609491003013328661</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>1357084800</td>\n",
       "      <td>Fight like this, Walking Dead. Both songs are ...</td>\n",
       "      <td>5</td>\n",
       "      <td>01 2, 2013</td>\n",
       "      <td>Decyfer Down at their best.</td>\n",
       "      <td>14.87</td>\n",
       "      <td>['CDs &amp; Vinyl', 'Rock', 'Hard Rock']</td>\n",
       "      <td>Rock</td>\n",
       "      <td>7453282935115361569</td>\n",
       "      <td>-3962525740789261387</td>\n",
       "      <td>SRE Records</td>\n",
       "      <td>2006.0</td>\n",
       "      <td>[-723861579512861737, -4694740640801132236, 27...</td>\n",
       "      <td>543899</td>\n",
       "      <td>{'also_bought': [6759112278599618175, -2155016...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>-84902388281572817</td>\n",
       "      <td>1683355681609577463</td>\n",
       "      <td>[0, 1]</td>\n",
       "      <td>1395619200</td>\n",
       "      <td>After seeing this selling on line for as much ...</td>\n",
       "      <td>4</td>\n",
       "      <td>03 24, 2014</td>\n",
       "      <td>Metallica - Death Magnetic (Deluxe Coffin Boxset)</td>\n",
       "      <td>99.99</td>\n",
       "      <td>['CDs &amp; Vinyl', 'Rock']</td>\n",
       "      <td>Rock</td>\n",
       "      <td>2278261453371246336</td>\n",
       "      <td>1178076565539150448</td>\n",
       "      <td>Mercury (Universal)</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>[6232524707980398149, 5566973718179316922, -43...</td>\n",
       "      <td>503636</td>\n",
       "      <td>{'also_viewed': [-5109793234044987754, 5931663...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>-8209243714021876578</td>\n",
       "      <td>245546254853962888</td>\n",
       "      <td>[1, 1]</td>\n",
       "      <td>1087430400</td>\n",
       "      <td>Let me start by saying that I am not a die-har...</td>\n",
       "      <td>5</td>\n",
       "      <td>06 17, 2004</td>\n",
       "      <td>Best Comedy Recording Ever</td>\n",
       "      <td>36.97</td>\n",
       "      <td>['CDs &amp; Vinyl', 'Dance &amp; Electronic']</td>\n",
       "      <td>Dance &amp; Electronic</td>\n",
       "      <td>-3282866979189163366</td>\n",
       "      <td>8493232817338375900</td>\n",
       "      <td>Enigma</td>\n",
       "      <td>1990.0</td>\n",
       "      <td>[-5143272649889793807, -547543979015767703, -8...</td>\n",
       "      <td>199821</td>\n",
       "      <td>{'also_bought': [5334117667833916410, 27299936...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>-2614895023138152712</td>\n",
       "      <td>245546254853962888</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>1364774400</td>\n",
       "      <td>Been looking for this CD for a while.  Descrip...</td>\n",
       "      <td>5</td>\n",
       "      <td>04 1, 2013</td>\n",
       "      <td>Awesome</td>\n",
       "      <td>36.97</td>\n",
       "      <td>['CDs &amp; Vinyl', 'Dance &amp; Electronic']</td>\n",
       "      <td>Dance &amp; Electronic</td>\n",
       "      <td>-3282866979189163366</td>\n",
       "      <td>8493232817338375900</td>\n",
       "      <td>Enigma</td>\n",
       "      <td>1990.0</td>\n",
       "      <td>[-5143272649889793807, -547543979015767703, -8...</td>\n",
       "      <td>199821</td>\n",
       "      <td>{'also_bought': [5334117667833916410, 27299936...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             reviewerID            amazon-id   helpful  unixReviewTime  \\\n",
       "30 -3029154682982670675  2828769427501176858  [13, 13]      1274486400   \n",
       "31 -6276416742486014581  1609491003013328661    [0, 0]      1357084800   \n",
       "32   -84902388281572817  1683355681609577463    [0, 1]      1395619200   \n",
       "33 -8209243714021876578   245546254853962888    [1, 1]      1087430400   \n",
       "34 -2614895023138152712   245546254853962888    [0, 0]      1364774400   \n",
       "\n",
       "                                           reviewText  overall   reviewTime  \\\n",
       "30  When I was in Music School at Stetson Universi...        5  05 22, 2010   \n",
       "31  Fight like this, Walking Dead. Both songs are ...        5   01 2, 2013   \n",
       "32  After seeing this selling on line for as much ...        4  03 24, 2014   \n",
       "33  Let me start by saying that I am not a die-har...        5  06 17, 2004   \n",
       "34  Been looking for this CD for a while.  Descrip...        5   04 1, 2013   \n",
       "\n",
       "                                              summary  price  \\\n",
       "30                              A Great Teaching tool  15.00   \n",
       "31                        Decyfer Down at their best.  14.87   \n",
       "32  Metallica - Death Magnetic (Deluxe Coffin Boxset)  99.99   \n",
       "33                         Best Comedy Recording Ever  36.97   \n",
       "34                                            Awesome  36.97   \n",
       "\n",
       "                                           categories          root-genre  \\\n",
       "30  ['CDs & Vinyl', 'Classical', 'Sacred & Religio...           Classical   \n",
       "31               ['CDs & Vinyl', 'Rock', 'Hard Rock']                Rock   \n",
       "32                            ['CDs & Vinyl', 'Rock']                Rock   \n",
       "33              ['CDs & Vinyl', 'Dance & Electronic']  Dance & Electronic   \n",
       "34              ['CDs & Vinyl', 'Dance & Electronic']  Dance & Electronic   \n",
       "\n",
       "                  title               artist                label  \\\n",
       "30 -3686601028207514605 -1412275221690118390             Solesmes   \n",
       "31  7453282935115361569 -3962525740789261387          SRE Records   \n",
       "32  2278261453371246336  1178076565539150448  Mercury (Universal)   \n",
       "33 -3282866979189163366  8493232817338375900               Enigma   \n",
       "34 -3282866979189163366  8493232817338375900               Enigma   \n",
       "\n",
       "    first-release-year                                              songs  \\\n",
       "30              2002.0  [-5278554366520980165, 1031059927497114547, -8...   \n",
       "31              2006.0  [-723861579512861737, -4694740640801132236, 27...   \n",
       "32              2008.0  [6232524707980398149, 5566973718179316922, -43...   \n",
       "33              1990.0  [-5143272649889793807, -547543979015767703, -8...   \n",
       "34              1990.0  [-5143272649889793807, -547543979015767703, -8...   \n",
       "\n",
       "    salesRank                                            related  \n",
       "30     171890  {'also_bought': [-2564721328448647001, 4039811...  \n",
       "31     543899  {'also_bought': [6759112278599618175, -2155016...  \n",
       "32     503636  {'also_viewed': [-5109793234044987754, 5931663...  \n",
       "33     199821  {'also_bought': [5334117667833916410, 27299936...  \n",
       "34     199821  {'also_bought': [5334117667833916410, 27299936...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df.shape)\n",
    "print(df[df['first-release-year'].notna()].shape)\n",
    "df[df['first-release-year'].notna()].head() # Returns rows where df['image'].notna() is true"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tip #1 for the project\n",
    "\n",
    "- NaN Values need to be dealt with as ML models have no clue what to do with them. You will have to determine if 1) the entire column should be dropped 2) only the rows with nan values should be dropped 3) the rows with nan values should be filled in with some number extracted from the available data. \n",
    "    - For example, if a product has no price, you can 1) not use price information at all 2) get rid of that sample 3) somehow infer the price from other information? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Pandas .apply() function\n",
    "In my opinion, this will be one of the most useful tools when dealing with pandas dataframes. apply() lets you apply a function to all cells of a column very efficiently. Below is an example of how we can convert the 'helpful' feature into a numeric value.\n",
    "\n",
    "Note, you can define your own function like 'convert_helpful' or, simply use a lambda function and have all your code live inside of the apply function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# literal_eval can take a string '[0,1]' and convert it to a list [0,1]\n",
    "# Sometimes, saving list objects as csv's causes them to be represented as strings\n",
    "# which is why we need to do this here. \n",
    "from ast import literal_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45    [10, 11]\n",
      "46      [4, 4]\n",
      "47      [0, 0]\n",
      "48    [13, 14]\n",
      "49      [2, 3]\n",
      "Name: helpful, dtype: object\n",
      "45    0.909091\n",
      "46    1.000000\n",
      "47         NaN\n",
      "48    0.928571\n",
      "49    0.666667\n",
      "Name: helpful, dtype: float64\n",
      "45    0.909091\n",
      "46    1.000000\n",
      "47         NaN\n",
      "48    0.928571\n",
      "49    0.666667\n",
      "Name: helpful, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "def convert_helpful(x):\n",
    "    x = literal_eval(x)\n",
    "    if x[1] == 0:\n",
    "        return np.nan\n",
    "    else:\n",
    "        return x[0]/x[1]\n",
    "\n",
    "# I use .iloc[45:50] here simply because these 5 samples\n",
    "# were more diverse than samples 1-5\n",
    "print(df['helpful'].iloc[45:50])\n",
    "print(df['helpful'].apply(convert_helpful).iloc[45:50])\n",
    "print(df['helpful'].apply(lambda x: np.nan if literal_eval(x)[1]== 0 else literal_eval(x)[0]/literal_eval(x)[1]).iloc[45:50])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Structuring the project for Binary Classification\n",
    "- Recall that we are using amazon review data to predict album ratings. More specifically, we want to see if a product review is over or under a certain threshold. For this problem, we say that an album is \"awesome\" if its average rating is over 4.5 (not inclusive). Otherwise, the product is \"not awesome\". The data is not given to us with a binary 1(over)/0(under) column.\n",
    "- Below, I will get you started on how to accomplish this with a pandas function called groupby. From here, you should be able to figure out how to make the target variable. \n",
    "- Many products in the training file will have more than one review. Thus, we need to find the average overall score for a product. \n",
    "- Groupby aggregates columns with the same values for you to then perform an operation on the aggregated columns. Below, I show the mean product review for each product. you could have also called .std() for standard deviation or defined your own function.\n",
    "\n",
    "Hint: Use .apply() to convert a groupby'd column to your target variable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>overall</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>amazon-id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>-9217723718720870868</th>\n",
       "      <td>4.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-9215746463819797371</th>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-9213978596308513604</th>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-9211290576571923870</th>\n",
       "      <td>4.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-9208769561690910545</th>\n",
       "      <td>4.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       overall\n",
       "amazon-id                     \n",
       "-9217723718720870868  4.333333\n",
       "-9215746463819797371  5.000000\n",
       "-9213978596308513604  3.000000\n",
       "-9211290576571923870  4.500000\n",
       "-9208769561690910545  4.500000"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg = df[['amazon-id', 'overall']].groupby('amazon-id').mean()\n",
    "avg.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A final note on pandas \n",
    "- First of all, Pandas is my favorite python library and I love talking about it so feel free to ask me any questions. \n",
    "- There are a few other functions I found useful that I wanted to mention for you to look up on your own. \n",
    "    - df.drop([list of columns] or [list of indices], axis = 1 or 0) -> the drop function will be useful for getting rid of unwated data. \n",
    "        - So for example, if you have the subet df[df['overall'] > 3], you can get the indices by calling .index and use these to drop them from the main df if you for some reason did not want ratings over 3. The same logic applies for columns. \n",
    "    - df.reset_index() will reset the dataframe index to start from 0 and count up. Sometimes when you process data the indices get mixed up and this can cause weird problems. Just remember that I said this. \n",
    "    - you can save these files with df.to_csv('filename.csv') - once you clean your data accordingly this might save you some time to do the processing first, then save the dataframe as a csv, then load the csv. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Scikit-Learn \n",
    "- Scikit-Learn is a machine learning library that will allow us to perform binary classification for our project. That is not to suggest that is all sklearn is capable of, as it is THE machine learning library. Take the time to get to know this as if you plan on working in ML, you will certainly be using Scikit-Learn at some point. \n",
    "- I am going to go over how to do classification on a toy dataset to give you an idea of how this API works. First, we will  download the iris dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['setosa' 'versicolor' 'virginica']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris # load a toy built-in dataset\n",
    "iris = load_iris()\n",
    "X = iris.data # get features\n",
    "column_names = iris.feature_names\n",
    "y = iris.target # get labels\n",
    "print(iris.target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
       "0                5.1               3.5                1.4               0.2   \n",
       "1                4.9               3.0                1.4               0.2   \n",
       "2                4.7               3.2                1.3               0.2   \n",
       "3                4.6               3.1                1.5               0.2   \n",
       "4                5.0               3.6                1.4               0.2   \n",
       "\n",
       "   target  \n",
       "0       0  \n",
       "1       0  \n",
       "2       0  \n",
       "3       0  \n",
       "4       0  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(X, columns = column_names) # sklearn works nicely with pandas\n",
    "df['target'] = y\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    50\n",
       "1    50\n",
       "0    50\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['target'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting our data into training and test sets. \n",
    "- In Machine Learning, we need to make sure we validate our models on unseen data as to ensure what we have learned will generalize to all situations and not simply memorize the given training data. There is a handy function in sklearn called train_test_split which makes this process very simple. \n",
    "- The function takes in all of your data and labels, and then you use test_size to determine what percent of your data should be reserved for testing. \n",
    "    - Note: There is also a parameter called stratify that might be worth looking into for this project if you come across any class imbalance in your random train/test splits. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full dataset shape:  150\n",
      "Train dataset shape:  105\n",
      "Test dataset shape:  45\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(df.drop('target', axis=1), df['target'], test_size = 0.3)\n",
    "print('Full dataset shape: ', df.shape[0])\n",
    "print('Train dataset shape: ', X_train.shape[0])\n",
    "print('Test dataset shape: ', X_test.shape[0]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performing classification\n",
    "\n",
    "- As you may have learned in class thus far, one way to perform classification is to use the naive bayes classification algorithm. The beautiful thing about sklearn is that it abstracts all of the complicated details about ML algorithms and only demands that we properly prepare the data. \n",
    "- All sklearn prediction models will follow the following design paradigm\n",
    "    - model.fit(X_train, y_train)\n",
    "    - predictions = model.predict(X_test)\n",
    "    - accuracy = model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9555555555555556"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "model = GaussianNB()\n",
    "model.fit(X_train, y_train)\n",
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tip #2 for the project. \n",
    "- Even though fitting and testing an sklearn model seems relatively easy, getting good results on more complex data (like amazon reviews) will require knowledge of how the model works as you will need to tune the hyperparameters accordingly. \n",
    "    - Make sure to understand how these classification algorithms work, read the documentation for them on sklearn's website, and look up what each of the hyperparameters do. Not only will this help your ML education but it will certainly help you get good results on the project. \n",
    "- Think about what evaluation metrics will best help you quantify how your model is performing. Accuracy is not always the best metric. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The hard part about this project\n",
    "- You have seen me do a quick classification model on the iris dataset. Note that this was so easy because we were given good features to learn from! In the amazon reviews challenge, you cannot simply pass the reviews to a naive bayes classifier as NB has no clue what to do with text. \n",
    "- The main challenge will be to find meaningful numeric features for the text data. These text features, along with the other available information (price, artist, etc.) will then be used to predict the binary target variable for each album.\n",
    "    - Please see the professors slide deck from lecture one on NLP for tips on where to start with generating these features. \n",
    "    - I included pip install nltk at the beginning of this notebook because this library will help you get started with creating these features. It will be key for pre-processing the data. pandas, sklearn, and numpy should have everything else you need as you are not allowed to use neural methods for prediction. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
